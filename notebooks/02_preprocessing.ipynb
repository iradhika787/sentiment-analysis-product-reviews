{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e71f78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to c:\\Users\\radhi\\AppData\\Lo\n",
      "[nltk_data]     cal\\Programs\\Python\\Python311\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to c:\\Users\\radhi\\AppData\\Loca\n",
      "[nltk_data]     l\\Programs\\Python\\Python311\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Sample:\n",
      "                                         review_text  rating sentiment\n",
      "0  Absolutely wonderful - silky and sexy and comf...       4  positive\n",
      "1  Love this dress!  it's sooo pretty.  i happene...       5  positive\n",
      "2  I love, love, love this jumpsuit. it's fun, fl...       5  positive\n",
      "3  This shirt is very flattering to all due to th...       5  positive\n",
      "4  I love tracy reese dresses, but this one is no...       2  negative\n",
      "\n",
      "Sample cleaned reviews:\n",
      "                                         review_text  \\\n",
      "0  Absolutely wonderful - silky and sexy and comf...   \n",
      "1  Love this dress!  it's sooo pretty.  i happene...   \n",
      "2  I love, love, love this jumpsuit. it's fun, fl...   \n",
      "3  This shirt is very flattering to all due to th...   \n",
      "4  I love tracy reese dresses, but this one is no...   \n",
      "\n",
      "                                        clean_review sentiment  \n",
      "0        absolutely wonderful silky sexy comfortable  positive  \n",
      "1  love dress sooo pretty happened find store im ...  positive  \n",
      "2  love love love jumpsuit fun flirty fabulous ev...  positive  \n",
      "3  shirt flattering due adjustable front tie perf...  positive  \n",
      "4  love tracy reese dress one petite foot tall us...  negative  \n",
      "Preprocessed data saved as: ../data/processed/preprocessed_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "\n",
    "# Create processed folder if missing\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load clean dataset\n",
    "df = pd.read_csv(\"../data/processed/clean_reviews.csv\")\n",
    "print(\"Dataset loaded. Sample:\")\n",
    "print(df.head())\n",
    "\n",
    "# Initialize tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = ToktokTokenizer()\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "df['clean_review'] = df['review_text'].apply(preprocess_text)\n",
    "\n",
    "print(\"\\nSample cleaned reviews:\")\n",
    "print(df[['review_text', 'clean_review', 'sentiment']].head())\n",
    "\n",
    "# Save preprocessed data\n",
    "df.to_csv(\"../data/processed/preprocessed_reviews.csv\", index=False)\n",
    "print(\"Preprocessed data saved as: ../data/processed/preprocessed_reviews.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
